{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45db91da-1f9d-4e8f-a417-57c233ded55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1/7...\n",
      "Request 2/7...\n",
      "Request 3/7...\n",
      "Request 4/7...\n",
      "Request 5/7...\n",
      "Request 6/7...\n",
      "Request 7/7...\n",
      "All requests have been sent successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "day = 86400\n",
    "url = 'https://meteoapi.xn--b1ahgiuw.xn--p1ai/parameter/'\n",
    "stationID = {\n",
    "    \"Сервисный центр\": '\"00001F76\"',\n",
    "    \"Отделение 17\": '\"00001F77\"',\n",
    "    \"Отделение 9\": '\"00001F78\"',\n",
    "    \"ПУ Север\": '\"0000235D\"',\n",
    "    \"ПУ Кавказ\": '\"0000235E\"',\n",
    "    \"Отделение 12\": '\"00001F7D\"',\n",
    "}\n",
    "stationParameters = {\n",
    "    1: '\"SOLAR_RADIATION\"',  # Солнечная радиация\n",
    "    2: '\"PRECIPITATION\"',  # Атмосферные осадки\n",
    "    3: '\"WIND_SPEED\"',  # Скорость ветра\n",
    "    4: '\"LEAF_WETNESS\"',  # Влажность листа\n",
    "    5: '\"HC_AIR_TEMPERATURE\"',  # Температура воздуха\n",
    "    6: '\"HC_RELATIVE_HUMIDITY\"',  # Влажность воздуха\n",
    "    7: '\"DEW_POINT\"'  # Точка росы\n",
    "}\n",
    "\n",
    "# Создаем пустой словарь для хранения данных\n",
    "data_dict = {}\n",
    "\n",
    "try:\n",
    "    for parameter in stationParameters:\n",
    "        t = int(time.time())\n",
    "        msg = {\n",
    "            \"meteoId\": stationID.get(\"Сервисный центр\").strip('\"'),\n",
    "            \"endTime\": t - day,\n",
    "            \"parameterName\": stationParameters.get(parameter).strip('\"'),\n",
    "            \"startTime\": t - 550 * day\n",
    "        }\n",
    "        response = requests.post(url, json=msg)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Request {parameter}/7...\")\n",
    "\n",
    "        data = response.json()\n",
    "        data_dict[stationParameters[parameter]] = data['values']['values']\n",
    "    print(f\"All requests have been sent successfully!\")\n",
    "\n",
    "    # Создаем DataFrame из полученных данных\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.rename(columns=lambda x: x.strip('\"'))\n",
    "    df.to_csv('meteo_data.csv', index=False)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Произошла ошибка при отправке запроса:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de7d45f-2f7d-43ac-a2cb-2cf7743fa66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SOLAR_RADIATION  WIND_SPEED  HC_AIR_TEMPERATURE  HC_RELATIVE_HUMIDITY  \\\n",
      "0                276.0         1.5               19.32                 47.16   \n",
      "1                178.0         1.1               19.61                 45.84   \n",
      "2                130.0         1.5               19.47                 44.81   \n",
      "3                 42.0         1.7               18.93                 45.42   \n",
      "4                  0.0         1.0               18.40                 47.91   \n",
      "...                ...         ...                 ...                   ...   \n",
      "13158            115.0         0.4                2.13                  0.00   \n",
      "13159            287.0         1.7                2.95                  0.00   \n",
      "13160            407.0         2.0                4.15                  0.00   \n",
      "13161            195.0         1.3                3.84                  0.00   \n",
      "13162            225.0         1.4                3.88                  8.33   \n",
      "\n",
      "       DEW_POINT  \n",
      "0            7.5  \n",
      "1            7.4  \n",
      "2            6.9  \n",
      "3            6.7  \n",
      "4            6.9  \n",
      "...          ...  \n",
      "13158        0.0  \n",
      "13159        0.0  \n",
      "13160        0.0  \n",
      "13161        0.0  \n",
      "13162        0.0  \n",
      "\n",
      "[13163 rows x 5 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "13158    0\n",
      "13159    0\n",
      "13160    0\n",
      "13161    0\n",
      "13162    0\n",
      "Name: PRECIPITATION, Length: 13163, dtype: int64\n",
      "Train dataset size: 10530, Test dataset size: 2633\n",
      "Epoch [10/3000], Loss: 0.6114, Train Accuracy: 0.90, Test Accuracy: 0.91\n",
      "Epoch [20/3000], Loss: 0.5926, Train Accuracy: 0.91, Test Accuracy: 0.92\n",
      "Epoch [30/3000], Loss: 0.5739, Train Accuracy: 0.91, Test Accuracy: 0.92\n",
      "Epoch [40/3000], Loss: 0.5555, Train Accuracy: 0.91, Test Accuracy: 0.92\n",
      "Epoch [50/3000], Loss: 0.5374, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [60/3000], Loss: 0.5199, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [70/3000], Loss: 0.5029, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [80/3000], Loss: 0.4866, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [90/3000], Loss: 0.4711, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [100/3000], Loss: 0.4563, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [110/3000], Loss: 0.4424, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [120/3000], Loss: 0.4294, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [130/3000], Loss: 0.4173, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [140/3000], Loss: 0.4060, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [150/3000], Loss: 0.3956, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [160/3000], Loss: 0.3860, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [170/3000], Loss: 0.3772, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [180/3000], Loss: 0.3691, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [190/3000], Loss: 0.3616, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [200/3000], Loss: 0.3547, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [210/3000], Loss: 0.3484, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [220/3000], Loss: 0.3425, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [230/3000], Loss: 0.3371, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [240/3000], Loss: 0.3320, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [250/3000], Loss: 0.3272, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [260/3000], Loss: 0.3227, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [270/3000], Loss: 0.3185, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [280/3000], Loss: 0.3146, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [290/3000], Loss: 0.3109, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [300/3000], Loss: 0.3075, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [310/3000], Loss: 0.3042, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [320/3000], Loss: 0.3012, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [330/3000], Loss: 0.2984, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [340/3000], Loss: 0.2958, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [350/3000], Loss: 0.2933, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [360/3000], Loss: 0.2911, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [370/3000], Loss: 0.2890, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [380/3000], Loss: 0.2872, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [390/3000], Loss: 0.2855, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [400/3000], Loss: 0.2840, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [410/3000], Loss: 0.2826, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [420/3000], Loss: 0.2814, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [430/3000], Loss: 0.2803, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [440/3000], Loss: 0.2793, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [450/3000], Loss: 0.2784, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [460/3000], Loss: 0.2775, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [470/3000], Loss: 0.2768, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [480/3000], Loss: 0.2761, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [490/3000], Loss: 0.2754, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [500/3000], Loss: 0.2749, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [510/3000], Loss: 0.2743, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [520/3000], Loss: 0.2738, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [530/3000], Loss: 0.2733, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [540/3000], Loss: 0.2728, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [550/3000], Loss: 0.2724, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [560/3000], Loss: 0.2720, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [570/3000], Loss: 0.2716, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [580/3000], Loss: 0.2713, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [590/3000], Loss: 0.2709, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [600/3000], Loss: 0.2706, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [610/3000], Loss: 0.2703, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [620/3000], Loss: 0.2700, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [630/3000], Loss: 0.2697, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [640/3000], Loss: 0.2694, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [650/3000], Loss: 0.2692, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [660/3000], Loss: 0.2689, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [670/3000], Loss: 0.2687, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [680/3000], Loss: 0.2685, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [690/3000], Loss: 0.2683, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [700/3000], Loss: 0.2681, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [710/3000], Loss: 0.2679, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [720/3000], Loss: 0.2677, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [730/3000], Loss: 0.2675, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [740/3000], Loss: 0.2673, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [750/3000], Loss: 0.2671, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [760/3000], Loss: 0.2669, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [770/3000], Loss: 0.2668, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [780/3000], Loss: 0.2666, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [790/3000], Loss: 0.2664, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [800/3000], Loss: 0.2663, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [810/3000], Loss: 0.2661, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [820/3000], Loss: 0.2660, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [830/3000], Loss: 0.2658, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [840/3000], Loss: 0.2657, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [850/3000], Loss: 0.2655, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [860/3000], Loss: 0.2654, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [870/3000], Loss: 0.2652, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [880/3000], Loss: 0.2651, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [890/3000], Loss: 0.2649, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [900/3000], Loss: 0.2648, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [910/3000], Loss: 0.2646, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [920/3000], Loss: 0.2645, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [930/3000], Loss: 0.2644, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [940/3000], Loss: 0.2642, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [950/3000], Loss: 0.2641, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [960/3000], Loss: 0.2640, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [970/3000], Loss: 0.2638, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [980/3000], Loss: 0.2637, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [990/3000], Loss: 0.2636, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1000/3000], Loss: 0.2635, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1010/3000], Loss: 0.2633, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1020/3000], Loss: 0.2632, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1030/3000], Loss: 0.2631, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1040/3000], Loss: 0.2630, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1050/3000], Loss: 0.2629, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1060/3000], Loss: 0.2628, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1070/3000], Loss: 0.2628, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1080/3000], Loss: 0.2627, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1090/3000], Loss: 0.2626, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1100/3000], Loss: 0.2625, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1110/3000], Loss: 0.2624, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1120/3000], Loss: 0.2623, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1130/3000], Loss: 0.2622, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1140/3000], Loss: 0.2622, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1150/3000], Loss: 0.2621, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1160/3000], Loss: 0.2620, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1170/3000], Loss: 0.2619, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1180/3000], Loss: 0.2619, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1190/3000], Loss: 0.2618, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1200/3000], Loss: 0.2617, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1210/3000], Loss: 0.2616, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1220/3000], Loss: 0.2615, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1230/3000], Loss: 0.2615, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1240/3000], Loss: 0.2614, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1250/3000], Loss: 0.2613, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1260/3000], Loss: 0.2612, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1270/3000], Loss: 0.2611, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1280/3000], Loss: 0.2610, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1290/3000], Loss: 0.2609, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1300/3000], Loss: 0.2609, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1310/3000], Loss: 0.2608, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1320/3000], Loss: 0.2607, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1330/3000], Loss: 0.2607, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1340/3000], Loss: 0.2606, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1350/3000], Loss: 0.2605, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1360/3000], Loss: 0.2605, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1370/3000], Loss: 0.2604, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1380/3000], Loss: 0.2603, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1390/3000], Loss: 0.2603, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1400/3000], Loss: 0.2602, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1410/3000], Loss: 0.2602, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1420/3000], Loss: 0.2601, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1430/3000], Loss: 0.2601, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1440/3000], Loss: 0.2600, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1450/3000], Loss: 0.2599, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1460/3000], Loss: 0.2599, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1470/3000], Loss: 0.2598, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1480/3000], Loss: 0.2598, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1490/3000], Loss: 0.2597, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1500/3000], Loss: 0.2596, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1510/3000], Loss: 0.2596, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1520/3000], Loss: 0.2595, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1530/3000], Loss: 0.2595, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1540/3000], Loss: 0.2594, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1550/3000], Loss: 0.2593, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1560/3000], Loss: 0.2593, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1570/3000], Loss: 0.2592, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1580/3000], Loss: 0.2591, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1590/3000], Loss: 0.2591, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1600/3000], Loss: 0.2590, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1610/3000], Loss: 0.2589, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1620/3000], Loss: 0.2589, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1630/3000], Loss: 0.2588, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1640/3000], Loss: 0.2588, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1650/3000], Loss: 0.2587, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1660/3000], Loss: 0.2587, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1670/3000], Loss: 0.2587, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1680/3000], Loss: 0.2586, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1690/3000], Loss: 0.2586, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1700/3000], Loss: 0.2585, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1710/3000], Loss: 0.2585, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1720/3000], Loss: 0.2585, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1730/3000], Loss: 0.2584, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1740/3000], Loss: 0.2584, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1750/3000], Loss: 0.2584, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1760/3000], Loss: 0.2583, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1770/3000], Loss: 0.2583, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1780/3000], Loss: 0.2582, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1790/3000], Loss: 0.2582, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1800/3000], Loss: 0.2582, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1810/3000], Loss: 0.2581, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1820/3000], Loss: 0.2581, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1830/3000], Loss: 0.2581, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1840/3000], Loss: 0.2580, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1850/3000], Loss: 0.2580, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1860/3000], Loss: 0.2579, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1870/3000], Loss: 0.2579, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1880/3000], Loss: 0.2579, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1890/3000], Loss: 0.2578, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1900/3000], Loss: 0.2578, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1910/3000], Loss: 0.2578, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1920/3000], Loss: 0.2577, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1930/3000], Loss: 0.2577, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1940/3000], Loss: 0.2577, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1950/3000], Loss: 0.2576, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1960/3000], Loss: 0.2576, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1970/3000], Loss: 0.2576, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1980/3000], Loss: 0.2575, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [1990/3000], Loss: 0.2575, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2000/3000], Loss: 0.2575, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2010/3000], Loss: 0.2574, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2020/3000], Loss: 0.2574, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2030/3000], Loss: 0.2574, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2040/3000], Loss: 0.2573, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2050/3000], Loss: 0.2573, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2060/3000], Loss: 0.2573, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2070/3000], Loss: 0.2572, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2080/3000], Loss: 0.2572, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2090/3000], Loss: 0.2572, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2100/3000], Loss: 0.2571, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2110/3000], Loss: 0.2571, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2120/3000], Loss: 0.2570, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2130/3000], Loss: 0.2570, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2140/3000], Loss: 0.2570, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2150/3000], Loss: 0.2569, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2160/3000], Loss: 0.2569, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2170/3000], Loss: 0.2568, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2180/3000], Loss: 0.2568, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2190/3000], Loss: 0.2568, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2200/3000], Loss: 0.2567, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2210/3000], Loss: 0.2567, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2220/3000], Loss: 0.2567, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2230/3000], Loss: 0.2566, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2240/3000], Loss: 0.2566, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2250/3000], Loss: 0.2566, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2260/3000], Loss: 0.2565, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2270/3000], Loss: 0.2565, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2280/3000], Loss: 0.2565, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2290/3000], Loss: 0.2564, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2300/3000], Loss: 0.2564, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2310/3000], Loss: 0.2564, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2320/3000], Loss: 0.2563, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2330/3000], Loss: 0.2563, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2340/3000], Loss: 0.2563, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2350/3000], Loss: 0.2562, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2360/3000], Loss: 0.2562, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2370/3000], Loss: 0.2562, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2380/3000], Loss: 0.2561, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2390/3000], Loss: 0.2561, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2400/3000], Loss: 0.2561, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2410/3000], Loss: 0.2560, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2420/3000], Loss: 0.2560, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2430/3000], Loss: 0.2560, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2440/3000], Loss: 0.2560, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2450/3000], Loss: 0.2559, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2460/3000], Loss: 0.2559, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2470/3000], Loss: 0.2559, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2480/3000], Loss: 0.2558, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2490/3000], Loss: 0.2558, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2500/3000], Loss: 0.2558, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2510/3000], Loss: 0.2557, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2520/3000], Loss: 0.2557, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2530/3000], Loss: 0.2557, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2540/3000], Loss: 0.2557, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2550/3000], Loss: 0.2556, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2560/3000], Loss: 0.2556, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2570/3000], Loss: 0.2556, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2580/3000], Loss: 0.2556, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2590/3000], Loss: 0.2555, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2600/3000], Loss: 0.2555, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2610/3000], Loss: 0.2555, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2620/3000], Loss: 0.2555, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2630/3000], Loss: 0.2555, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2640/3000], Loss: 0.2554, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2650/3000], Loss: 0.2554, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2660/3000], Loss: 0.2554, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2670/3000], Loss: 0.2554, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2680/3000], Loss: 0.2553, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2690/3000], Loss: 0.2553, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2700/3000], Loss: 0.2553, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2710/3000], Loss: 0.2553, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2720/3000], Loss: 0.2552, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2730/3000], Loss: 0.2552, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2740/3000], Loss: 0.2552, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2750/3000], Loss: 0.2552, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2760/3000], Loss: 0.2552, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2770/3000], Loss: 0.2551, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2780/3000], Loss: 0.2551, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2790/3000], Loss: 0.2551, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2800/3000], Loss: 0.2551, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2810/3000], Loss: 0.2551, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2820/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2830/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2840/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2850/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2860/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2870/3000], Loss: 0.2550, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2880/3000], Loss: 0.2549, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2890/3000], Loss: 0.2549, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2900/3000], Loss: 0.2549, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2910/3000], Loss: 0.2549, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2920/3000], Loss: 0.2549, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2930/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2940/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2950/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2960/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2970/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2980/3000], Loss: 0.2548, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [2990/3000], Loss: 0.2547, Train Accuracy: 0.92, Test Accuracy: 0.92\n",
      "Epoch [3000/3000], Loss: 0.2547, Train Accuracy: 0.92, Test Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = df[['SOLAR_RADIATION', 'WIND_SPEED', 'HC_AIR_TEMPERATURE', 'HC_RELATIVE_HUMIDITY', 'DEW_POINT']]\n",
    "y = df['PRECIPITATION'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "# Разделение данных на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Конвертация данных в тензоры PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "print(f'Train dataset size: {len(X_train_tensor)}, Test dataset size: {len(X_test_tensor)}')\n",
    "\n",
    "# Создание нейронной сети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Определение параметров сети\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 10\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели с вычислением точности на каждой эпохе\n",
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Вычисление точности на тренировочном наборе\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model(X_train_tensor)\n",
    "        train_predicted = torch.round(train_outputs)\n",
    "        train_accuracy = (train_predicted == y_train_tensor.view(-1, 1)).sum().item() / len(y_train_tensor)\n",
    "    \n",
    "    # Вычисление точности на тестовом наборе\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_predicted = torch.round(test_outputs)\n",
    "        test_accuracy = (test_predicted == y_test_tensor.view(-1, 1)).sum().item() / len(y_test_tensor)\n",
    "    \n",
    "    # Вывод информации о потерях, точности и размере выборок\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}, Test Accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5289235b-5da6-4f92-a43c-2b84e19665e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([[2.5010e-15]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Подготовьте запрос (данные) в виде тензора PyTorch\n",
    "query_tensor = torch.tensor([[0.0, 0.0, 15.57, 75, 0]])  # Пример данных запроса\n",
    "\n",
    "# Передайте запрос в модель для предсказания\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    prediction = model(query_tensor)\n",
    "\n",
    "# Интерпретируйте предсказание (например, распакуйте вероятности классов или выходные значения)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6226684-ee80-4053-afc8-e1f84ea4b518",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train)\n\u001b[0;32m     53\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\PycharmProjects\\meteoApp\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\meteoApp\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 33\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     32\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[1;32m---> 33\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('meteo_data.csv')  # Замените 'your_data.csv' на путь к вашему файлу данных\n",
    "X = data[['SOLAR_RADIATION', 'WIND_SPEED', 'HC_AIR_TEMPERATURE', 'HC_RELATIVE_HUMIDITY', 'DEW_POINT']]\n",
    "y = data['PRECIPITATION']\n",
    "\n",
    "# Преобразование DataFrame в массивы numpy\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "\n",
    "# Преобразование массивов numpy в тензоры PyTorch\n",
    "X_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1)  # Добавляем измерение для столбца\n",
    "\n",
    "# Разделение данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Инициализация модели\n",
    "input_size = 13163  # Получаем размер входных признаков\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Оценка производительности модели на тестовом наборе\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "    print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110050ad-a08a-4293-a6c0-ea4c450e67da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
